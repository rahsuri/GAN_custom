# -*- coding: utf-8 -*-
"""GAN_alpha.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1njoQ-CFQJv4M6GD0Yu0qSMAgGWnCFhEq
"""

#Libraries / Datasets
import cv2
#numpy!
import numpy as np

#visualization
import matplotlib.pyplot as plt

#our main machine learning library - used to make neural network layers / model
import tensorflow as tf

#used to import our dataset that we will be using - fashion_mnist dataset
import tensorflow_datasets as tfds

#getting the dataset choice from user
dataset_choice = input("""Please enter the dataset you would like to use. If you
 are unsure of your options, select a dataset from
 https://www.tensorflow.org/datasets/catalog/overview or type "Null" to use the
 default fashion dataset.""")

if dataset_choice == "Null":
    dataset_choice =  "fashion_mnist"

ds = tfds.load(dataset_choice, split="train")
it = ds.as_numpy_iterator() #setting up an iterator to extract data once piece at a time

#now importing our model layers and components
from keras.layers import Dense, LeakyReLU, Conv2D, Flatten, Reshape, Dropout, UpSampling2D
from keras import Sequential
from keras.models import Model

#losses and optimizers for training
from keras.optimizers import Adam
from keras.losses import BinaryCrossentropy

#used to limit vram scaling while running our program to prevent memory
#issues. commented out since we are using a cloud computer

# gpus = tf.config.experimental.list_physical_devices("GPU")
# for gpu in gpus:
#     tf.config.experimental.set_memory_growth(gpu, True)

#creating a visualization of our raw data

plot, ax = plt.subplots(ncols = 4, figsize=(20,20))

#custom labels for fashion items
def label(x):
    if x==0:
        return 't-shirt'
    elif x==1:
        return 'pant'
    elif x==2:
        return 'sweater'
    elif x==3:
        return 'dress'
    elif x==4:
        return 'jacket'
    elif x==5:
        return 'sandal'
    elif x==6:
        return 'shirt'
    elif x==7:
        return 'sneaker'
    elif x==8:
        return 'bag'
    elif x==9:
        return 'boot'
#iterating through 4 random images and visualizing them
for i in range(4):
    batch = it.next()

    #showing the image
    ax[i].imshow(np.squeeze(batch['image']))
    #adding the label

    #here we are adding custom labels if the fashion dataset is used.
    #default labels if anything else is used.
    if dataset_choice == "fashion_mnist":
        ax[i].title.set_text(label(batch['label']))
    else:
        ax[i].title.set_text(label(batch['label']))



#now we are preprocessing our image pipeline so we can feed it into the network

#to do this, we must first gather some parameters from the user.
batch_size_choice = int(input("""Please enter your batch size. This will be the #
of images that are used in every training step. Enter 0 if using fashion."""))

resize_choice = int(input("""Please enter the resize value of your images. Make
sure that the value is divisible by 4, or else it will not work properly running
through the network. Recommended max is 100. Enter 0 for Fashion, 1 for
default."""))

while resize_choice % 4 != 0:
    resize_choice = int(input("""Number chosen is not divisible by 4. Please
    choose another."""))

if batch_size_choice == 0:
    batch_size_choice = 128

if resize_choice == 0:
    resize_choice = 28
elif resize_choice == 1:
    resize_choice = 48

resize_d = resize_choice

resize_choice = (resize_choice, resize_choice)
#scaling function so that we can compute our images as if they were greyscale.
# this makes it so that the images only have 1 channel and thus our network will
# not take as long to run, vs. 3 channels in RGB. Since RGB has values from
# 1-225, this will allow us to get values from 0-1, white to black.
# def scaling(data, resize):
#     image = data['image']
#     return image / 255

def preprocess_image(data, target_size):
    image = data['image']

    # Resize the image to the target dimensions
    image = tf.image.resize(image, target_size)

    # Normalize pixel values to [0, 1] range
    image = image / 255.0

    return image


#now we want to do our standard procedure for getting a training set ready:

#-reload dataset
ds = tfds.load(dataset_choice, split='train')
# -map
# scales all the images in our dataset at once
ds = ds.map(lambda x: preprocess_image(x,resize_choice))
# -cache
# used to optimize the retrieval of data
ds = ds.cache()
# -shuffle
# shuffling so sorted data is randomized
ds = ds.shuffle(60000)
# -batch
# setting the size of the batch used for every training step
ds = ds.batch(batch_size_choice)
# -prefetch
# used to to optimize data retrieval
ds = ds.prefetch(int(batch_size_choice/2))

#just to see the shapa of a peice of data we are using in the order of:
# (batch size, x-axis of image array, y-axis of image array, 1[since it is greyscale])
ds.as_numpy_iterator().next().shape

#now we will be building our generator model.

x1 = int(resize_d / 4)

y1 = int(resize_d / 4)

x2 = int(resize_d / 2)

y2 = int(resize_d / 2)

#the size will refer to the size parameter of our input
def build_generator():
    model = Sequential()

    #(1) create a random image and reshape it to 7x7x128
    model.add(Dense(x1*y1*batch_size_choice, input_dim=batch_size_choice))
    model.add(LeakyReLU(0.2))
    model.add(Reshape((x1,y1,batch_size_choice)))

    #(2) upsample our image so we get closer to original image dimensions
    model.add(UpSampling2D())
    model.add(Conv2D(batch_size_choice, 5, padding='same'))
    model.add(LeakyReLU(0.2))

    #(3) convolutional layer for sophistication
    model.add(Conv2D(batch_size_choice, 4, padding='same'))
    model.add(LeakyReLU(0.2))

    #(4) upsample once again to reach correct x and y dimensions (not yet z)
    model.add(UpSampling2D())
    model.add(Conv2D(batch_size_choice, 5, padding='same'))
    model.add(LeakyReLU(0.2))

    #(5) convolutional layer for sophistication
    model.add(Conv2D(batch_size_choice, 4, padding='same'))
    model.add(LeakyReLU(0.2))

    #(6) convolutional layer ''
    model.add(Conv2D(batch_size_choice, 4, padding='same'))
    model.add(LeakyReLU(0.2))

    #(6) final conv layer to reshape back to original shape
    model.add(Conv2D(1, 4 ,padding='same', activation='sigmoid'))

    return model

#now, we are building our discriminator model.

def build_discrim():

    model = Sequential()

    #(1) input conv layer
    model.add(Conv2D(32, 5, input_shape = (resize_d,resize_d,1)))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))

    #(2) second conv layer
    model.add(Conv2D(64, 5))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))

    #(3) third conv layer
    model.add(Conv2D(128,5))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))

    #(4) fourth conv layer
    model.add(Conv2D(256,5))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))

    #(5) flatten then pass through a connected layer
    model.add(Flatten())
    model.add(Dropout(0.4))
    model.add(Dense(1, activation = 'sigmoid'))

    return model

#now, last but not least, we must setup the training loop

#optimizers
g_opt = Adam(learning_rate=0.0001)
d_opt = Adam(learning_rate=0.00001)

#losses
g_loss = BinaryCrossentropy()
d_loss = BinaryCrossentropy()

class GAN(Model):
    def __init__(self, generator, discriminator, *args, **kwargs):
        # pass through args and kwargs
        super().__init__(*args, **kwargs)

        #creating attributes for our gen and disc
        self.generator = generator
        self.discriminator = discriminator

    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):

        super().compile(*args, **kwargs)

        #now creating attributes for our losses and opts
        self.g_opt = g_opt
        self.d_opt = d_opt
        self.g_loss = g_loss
        self.d_loss = d_loss

    def train_step(self, batch):

        #generating real and fake images
        real_images = batch
        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)

        with tf.GradientTape() as d_tape:
            #passing real and fake images to the discrim model
            yhat_real = self.discriminator(real_images, training=True)
            yhat_fake = self.discriminator(fake_images, training=True)
            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)

            #create labels for the real and fake images (essentially our labelled data)
            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)

            #add some noise to the outputs
            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))
            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))
            y_realfake += tf.concat([noise_real, noise_fake], axis=0)

            #calculate our losses
            total_d_loss = self.d_loss(y_realfake, yhat_realfake)

        #and lastly apply our backpropagation to adjust our parameters
        d_grad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)
        self.d_opt.apply_gradients(zip(d_grad, self.discriminator.trainable_variables))

        with tf.GradientTape() as g_tape:
            #generate some new images
            g_images = self.generator(tf.random.normal((128 ,128 ,1)), training=True)

            #create labels for images
            predict_labels = self.discriminator(g_images, training=False)

            #calculate losses - faking out our discriminator
            total_g_loss = self.g_loss(tf.zeros_like(predict_labels), predict_labels)

        #apply backprop
        g_grad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)
        self.g_opt.apply_gradients(zip(g_grad, self.generator.trainable_variables))

        return{"d_loss":total_d_loss, "g_loss":total_g_loss}

#Final Testing

#First we must make instances of our Discriminator and our Generator Networks

###Generator:
gen_network = build_generator()

#summary of generator:
gen_network.summary()

#Test Run
img = gen_network.predict(np.random.randn(4,128,1))

#plotting our test images (untrained as of now)
plot, ax = plt.subplots(ncols = 4, figsize=(20,20))
for i in range(4):

    #showing the image
    ax[i].imshow((np.squeeze(img[i])))

###Discrminator:
disc_network = build_discrim()

#Test Run using generated images:
print("Test Predictions:",disc_network.predict(img))

###Finally, creating an instance of our GAN
FashGAN = GAN(gen_network, disc_network)

#compiling using our optimizers and losses
FashGAN.compile(g_opt, d_opt, g_loss, d_loss)

#Training - epochs is recommended to be 2000 for actual results - more for high
# resolution images.
hist = FashGAN.fit(ds, epochs=20)

###Last but not least, we will...
# - See how the training went
# - Test out our trained models

#Training Results:
plt.suptitle('Loss')
plt.plot(hist.history["d_loss"], label="d_loss")
plt.plot(hist.history["g_loss"], label="g_loss")
plt.legend()
plt.show()
#Goal is for the g and d losses to equalize at one low value. As you can see,
#more epochs correlates to more equalization.

#Generate Images:
results = gen_network.predict(tf.random.normal((16,128,1)))

plot, ax = plt.subplots(ncols=4, nrows=4, figsize=(20,20))

for r in range(4):
    for c in range(4):
        ax[r][c].imshow(results[(r+1)*(c+1)-1])

###Now, if you would like you can save the model that you have created.
save_choice = input("Would you like to save your model?(Y/N)")

if save_choice.lower()=="y":
    gfilename = input("Please enter the filename for your generator model:")
    dfilename = input("Please enter the filename for your generator model:")
    gen_network.save("{}.h5".format(gfilename))
    disc_network.save("{}.h5".format(dfilename))